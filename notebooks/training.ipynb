{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'state' from '/home/justiny/Documents/Projects/PyDominion/src/state.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 434
    }
   ],
   "source": [
    "import state\n",
    "import predictor\n",
    "importlib.reload(predictor)\n",
    "importlib.reload(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiutils import load\n",
    "from mlp import PredictorMLP\n",
    "from mlprunner import train_mlp\n",
    "from config import GameConfig\n",
    "from player import load_players\n",
    "from enums import StartingSplit, FeatureType\n",
    "from predictor import sample_training_batch, test_mlp\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from state import ReducedStateFeature\n",
    "from supply import Supply\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GameConfig(split=StartingSplit.StartingRandomSplit, prosperity=False, num_players=2, feature_type=FeatureType.ReducedFeature, sandbox=True)\n",
    "players = load_players(['BM', 'BM'], models=None, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  2%|▏         | 15/1000 [00:00<00:06, 144.25it/s]Generating training data from self-play...\n",
      "100%|██████████| 1000/1000 [00:06<00:00, 144.88it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y = sample_training_batch(1000, -1, config, players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rand_10k = X.copy()\n",
    "y_rand_10k = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PredictorMLP(config.feature_size, (config.feature_size + 1) // 2, 1)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = '/home/justiny/Documents/Projects/PyDominion'\n",
    "model_dir = os.path.join(project_root, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'r-r-mlp-pred-bce-100-100-1'\n",
    "model_path = os.path.join(model_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 15%|█▌        | 2644/17476 [00:00<00:00, 26438.89it/s]Generating dataset for dataloader...\n",
      "100%|██████████| 17476/17476 [00:01<00:00, 13083.33it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]Training MLP...\n",
      "100%|██████████| 100/100 [21:20<00:00, 12.81s/it]\n"
     ]
    }
   ],
   "source": [
    "y1 = np.array(y, dtype=np.float32)\n",
    "train_mlp(X, y1, model, criterion, epochs=100, save_epochs=10, model_name=model_name, path=os.path.join(model_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(torch.tensor(X).cuda()).detach().cpu().numpy()\n",
    "y_labels = np.array(y).reshape(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = (y_pred > 0.5)\n",
    "correct = (output == y_labels).sum() \n",
    "acc  = correct / len(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7853855651588282"
      ]
     },
     "metadata": {},
     "execution_count": 332
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.11117749924175713"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "mean_squared_error(y_pred, y_labels)"
   ]
  },
  {
   "source": [
    "Let's try a simpler logistic regression model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "max_iter = 10e5\n",
    "model = LogisticRegression(max_iter=max_iter, C=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/home/justiny/Documents/Projects/PyDominion/models/r-r-mlp-pred-bce-10k-50--1'"
      ]
     },
     "metadata": {},
     "execution_count": 514
    }
   ],
   "source": [
    "project_root = '/home/justiny/Documents/Projects/PyDominion'\n",
    "model_dir = os.path.join(project_root, 'models')\n",
    "model_name = 'r-r-mlp-pred-bce-10k-50--1'\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PredictorMLP(\n",
       "  (fc1): Linear(in_features=21, out_features=11, bias=True)\n",
       "  (fc2): Linear(in_features=11, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 516
    }
   ],
   "source": [
    "model = load(model_path)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = model.fit(X_rand_10k, y_rand_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "metadata": {},
     "execution_count": 493
    }
   ],
   "source": [
    "reg.score(X, y)"
   ]
  },
  {
   "source": [
    "Copper, Curse, Estate, Duchy, Province, Silver, Gold"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([-6.25388341e-03, -1.99098762e+00,  1.95044124e+00,  5.81198855e+00,\n",
       "         1.12843042e+01,  9.18387473e-03, -6.30930290e-03]),\n",
       " array([-4.52886488e-04,  1.98728527e+00, -1.95562452e+00, -5.96425122e+00,\n",
       "        -1.12368846e+01, -2.42450308e-02,  6.80101895e-03]),\n",
       " array([-0.00034741]))"
      ]
     },
     "metadata": {},
     "execution_count": 494
    }
   ],
   "source": [
    "reg.coef_[0][7:14], reg.coef_[0][14:], reg.intercept_"
   ]
  },
  {
   "source": [
    "Save the logistic regression model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(reg, open(model_path, 'wb'))"
   ]
  },
  {
   "source": [
    "Let's test the logistic regression model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = GameConfig(split=StartingSplit.StartingRandomSplit, prosperity=False, num_players=2, feature_type=FeatureType.ReducedFeature, sandbox=True)\n",
    "test_players = load_players(['BM', 'BM'], models=None, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  2%|▏         | 15/1000 [00:00<00:07, 137.80it/s]Generating training data from self-play...\n",
      "100%|██████████| 1000/1000 [00:07<00:00, 142.48it/s]\n"
     ]
    }
   ],
   "source": [
    "test_X, test_y = sample_training_batch(1000, -1, test_config, test_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=1000000.0)"
      ]
     },
     "metadata": {},
     "execution_count": 371
    }
   ],
   "source": [
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.837"
      ]
     },
     "metadata": {},
     "execution_count": 497
    }
   ],
   "source": [
    "reg.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([-0.0155073 ,  0.        ,  0.        ,  0.1493008 , -0.05038149,\n",
       "         0.00025177, -0.01159875]),\n",
       " array([-6.25388341e-03, -1.99098762e+00,  1.95044124e+00,  5.81198855e+00,\n",
       "         1.12843042e+01,  9.18387473e-03, -6.30930290e-03]),\n",
       " array([-4.52886488e-04,  1.98728527e+00, -1.95562452e+00, -5.96425122e+00,\n",
       "        -1.12368846e+01, -2.42450308e-02,  6.80101895e-03]),\n",
       " array([-0.00034741]))"
      ]
     },
     "metadata": {},
     "execution_count": 509
    }
   ],
   "source": [
    "reg.coef_[0][:7], reg.coef_[0][7:14], reg.coef_[0][14:], reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_classes = reg.predict(test_X)\n",
    "err = test_X[test_X_classes != test_y]\n",
    "i=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([7., 0., 3., 0., 4., 6., 5.], dtype=float32),\n",
       " array([ 7.,  0.,  3.,  0.,  4., 10.,  1.], dtype=float32))"
      ]
     },
     "metadata": {},
     "execution_count": 507
    }
   ],
   "source": [
    "err[i][7:14], err[i][14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[0.46916815, 0.53083185]]), 1)"
      ]
     },
     "metadata": {},
     "execution_count": 508
    }
   ],
   "source": [
    "reg.predict_proba([err[i]]), y[i]"
   ]
  },
  {
   "source": [
    "MLP Testing\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = '/home/justiny/Documents/Projects/PyDominion'\n",
    "model_dir = os.path.join(project_root, 'models')\n",
    "model_name = 'r-r-mlp-pred-bce-10k-50--1'\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model(torch.tensor(test_X)).detach().cpu().numpy()\n",
    "y_test_labels = np.array(test_y).reshape(y_test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = (y_test_pred > 0.5)\n",
    "correct = (output == y_test_labels).sum() \n",
    "incorrect_flags = (output != y_test_labels).flatten()\n",
    "incorrect = test_X[incorrect_flags]\n",
    "incorrect_prob = y_test_pred[incorrect_flags]\n",
    "acc  = correct / len(y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.983"
      ]
     },
     "metadata": {},
     "execution_count": 519
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([7., 0., 4., 0., 4., 6., 4.], dtype=float32),\n",
       " array([7., 0., 3., 0., 4., 7., 4.], dtype=float32),\n",
       " array([0.01174975], dtype=float32))"
      ]
     },
     "metadata": {},
     "execution_count": 581
    }
   ],
   "source": [
    "incorrect[i][7:14], incorrect[i][14:], incorrect_prob[i]b"
   ]
  }
 ]
}